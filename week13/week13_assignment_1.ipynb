{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc1c39d0d6f8b82a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Week 13 Review Assignmnet\n",
    "\n",
    "For the questions below, we're going to refer exclusively to an HHCAPS survey data set that is available in `/data/hhcaps.csv`.  Use whatever commands you want to calculate the information required to get to the answer.  Then, enter your answer in the answers cell as usual.\n",
    "\n",
    "**NOTE: Enter your answers as string values (inside quotation marks \"\") even if the answer is actually numeric.**\n",
    "\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "hhcaps = pd.read_csv('/data/hhcaps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q01-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #01 - \n",
    "\n",
    "How many columns does this file contain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write some code to figure it out\n",
    "column_count = len(hhcaps.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from numpy import int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_count = int64(column_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q01-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answers={}\n",
    "answers['40.1'] = column_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q02-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #02 - \n",
    "\n",
    "How many different values for State are there in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write some code to figure it out\n",
    "state_count = len(hhcaps['State'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q02-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "answers['40.2'] = state_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q03-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #03 - \n",
    "\n",
    "Which of those State values has the highest frequency of occurence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q03-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Write some code to figure it out\n",
    "states_max = hhcaps['State'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q03-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "answers['40.3'] = states_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q04-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #04 - \n",
    "\n",
    "Which of those State values has the best average performance on the `Star Rating for health team communicated well with them` score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q04-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Write some code to figure it out\n",
    "state_groups = hhcaps.groupby('State')\n",
    "best_avg = state_groups['Star Rating for health team communicated well with them'].mean()\n",
    "best_avg_state = best_avg[best_avg == best_avg.max()].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q04-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "answers['40.4'] = best_avg_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q05-intro",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## #05 - \n",
    "\n",
    "What was the average score on `Star Rating for how patients rated overall care from agency` for providers listed as having a `Type of Ownership` of `Hospital Based Program`\n",
    "\n",
    "**NOTE: Enter your answer with two decimal precision: 0.00**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q05-solution",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Write some code to figure it out\n",
    "hosp_based = hhcaps['Type of Ownership'] == 'Hospital Based Program'\n",
    "hhcaps = hhcaps[hosp_based]\n",
    "hb_avg_score = round(hhcaps['Star Rating for how patients rated overall care from agency'].mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q05-test",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "answers['40.5'] = hb_avg_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Checking Your Work\n",
    "---\n",
    "\n",
    "After completing your work above and running each cell, you can check your answers by running the code below. \n",
    "\n",
    "The easiest way to do this is to use the `Kernel` -> `Restart Kernel and Run All Cells` menu option. This option restarts Python and runs every cell from top to bottom until it encounters an exception of some kind.  It will stop after running the cell below and outputing a summary of how many answers you have correct or incorrect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Q#               Yours  Correct?\n",
      " 40.1                  39        OK\n",
      " 40.2                  55        OK\n",
      " 40.3                  TX        OK\n",
      " 40.4                  ME        OK\n",
      " 40.5                3.69        OK\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "test = {\n",
    "    \"user\": getpass.getuser(),\n",
    "    \"week\": \"week13\",\n",
    "    \"answers\": answers\n",
    "}\n",
    "\n",
    "client = boto3.client('lambda')\n",
    "\n",
    "response = client.invoke(\n",
    "    FunctionName=\"hds5210\",\n",
    "    InvocationType=\"RequestResponse\",\n",
    "    Payload=json.dumps(test))\n",
    "\n",
    "result = json.loads(response['Payload'].read().decode('utf-8'))\n",
    "# print(result)\n",
    "\n",
    "try:\n",
    "    print('{0:>5}{1:>20}{2:>10}'.format('Q#','Yours','Correct?'))\n",
    "    for row in result.get('results'):\n",
    "        print('{0:>5}{1:>20}{2:>10}'.format(str(row[0]),str(row[1]),str(row[2])))\n",
    "except:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Check your work above\n",
    "\n",
    "If you didn't get them all correct, take a few minutes to think through those that aren't correct.\n",
    "\n",
    "\n",
    "## Submitting Your Work\n",
    "\n",
    "Submit your work as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
