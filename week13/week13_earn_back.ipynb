{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 13 - Earn-Back Points Assignment #3\n",
    "\n",
    "These exercises are entirely optional, but they provide good practice. And you can use them to earn extra points toward your semester grade.  Each problem in this notebook can you earn you back up to 2 points.  There are key requirements, though. If your code does not following these rules, you will earn no points for your work.\n",
    "* You MUST include docstrings that explain the purpose of your code.\n",
    "* You MUST include at least 2 example tests in your docstrings for each function you write.\n",
    "* You MUST run your docstrings within the notebook to show me your code and docstrings work correctly.\n",
    "* You MUST submit your own individual work.  You may not collaborate with other students on these assignments.\n",
    "\n",
    "There will be 4 assignments like this between now and the end of the semester, each with 4 problems, each worth 2 points, for a total of 32 points.\n",
    "\n",
    "**If anything about the above rules is unclear, please message me on Canvas or via email**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earn-Back 1: Fetal Activity Data\n",
    "\n",
    "Cardiotocograms are a useful tool for monitoring the health of fetuses and potential mortality of fetuses and pregnant women. This [dataset on Kaggle](https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification?resource=download) is a collection of measurements 2,126 test subjects. Let's do some interesting things with this data!\n",
    "\n",
    "I've already downloaded it and put in the Jupyter server under /data/fetal_health.csv\n",
    "\n",
    "Your first step is to write a python function called **risk_score()** that takes three input parameters (shown below) and returns back a new series computed using the following rules to compute a total risk score:\n",
    "* If the histograph number of peaks is greater than 5, add 1 to the risk score\n",
    "* If the number of accelerations per second is greater than 0.01, add 1 to the risk score\n",
    "* If the number of light decelerations per second is greather than 0.005, add 1 to the risk score\n",
    "\n",
    "*Note that these rules were made up by the instructor. They have no scientific basis behind them.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/data/fetal_health.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_score(peak, acceleration, deceleration):\n",
    "    \"\"\"(int, float, float)->int\n",
    "    This function will use the number of peaks on a histograph, accelerations per second, and light decelerations per second from fetal\n",
    "    cardiotocograms to compute a risk score. If a parameter meets its assigned threshold, the score increases by 1 which can be at most 3.\n",
    "    \n",
    "    >>> risk_score(6, 0.017, 0.0062)\n",
    "    3\n",
    "    \n",
    "    >>> risk_score(1, 0.02, 0.0051)\n",
    "    2\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    \n",
    "    if peak > 5:\n",
    "        score += 1\n",
    "    \n",
    "    if acceleration > 0.01:\n",
    "        score += 1\n",
    "        \n",
    "    if deceleration > 0.005:\n",
    "        score += 1\n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert risk_score(2, 0.0, 0.0) == 0\n",
    "assert risk_score(6, 0.006, 0.003) == 1\n",
    "assert risk_score(5, 0.015, 0.0) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    risk_score(6, 0.017, 0.0062)\n",
      "Expecting:\n",
      "    3\n",
      "ok\n",
      "Trying:\n",
      "    risk_score(1, 0.02, 0.0051)\n",
      "Expecting:\n",
      "    2\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(risk_score, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Earn-Back Part 2: Score the Data\n",
    "\n",
    "In this next step, write a function called **score_subjects()** that takes your whole Dataframe as input and returns a new Series with scores for every record.  I recommend doing this with the `apply()` function similar to the BMI example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29.411765\n",
       "1    30.470914\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create our sample dataframe\n",
    "people = pd.DataFrame([\n",
    "    ['Joe', 170, 85],\n",
    "    ['Alex', 190, 110]\n",
    "], columns=['Name','Height (cm)','Weight (kg)'])\n",
    "\n",
    "# 2. Define our function just like we would a normal function to calculate BMI\n",
    "def bmi(height_cm, weight_kg):\n",
    "    return weight_kg / ((height_cm/100) ** 2)\n",
    "\n",
    "# 3. Apply the bmi() function to each row using a lambda function\n",
    "#    Set \"axis=1\" to apply the function to each row (instead of column)\n",
    "#    Use an anonymous \"lambda\" function to call bmi function\n",
    "#    passing the height and weight columns from our dataframe.\n",
    "people.apply(lambda x: bmi(x['Height (cm)'],x['Weight (kg)']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Your Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_subjects(dataframe):\n",
    "    \"\"\"(pandas dataframe)->series\n",
    "    This function will read the passed through dataframe and call upon the risk_score() function to produce a risk score for every entry\n",
    "    using three of the dataframe columns. It returns a series of scores.\n",
    "    \n",
    "    >>> round(score_subjects(df).mean(),2)\n",
    "    0.47\n",
    "    \n",
    "    >>> score_subjects(df).median()\n",
    "    0.0\n",
    "    \"\"\"\n",
    "    return dataframe.apply(lambda x: risk_score(x['histogram_number_of_peaks'], x['accelerations'], x['light_decelerations']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(score_subjects(df).value_counts()) == 4\n",
    "assert max(score_subjects(df)) == 3\n",
    "assert min(score_subjects(df)) == 0\n",
    "assert score_subjects(df).value_counts()[0] == 1341\n",
    "assert score_subjects(df).value_counts()[1] == 574"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding tests in NoName\n",
      "Trying:\n",
      "    round(score_subjects(df).mean(),2)\n",
      "Expecting:\n",
      "    0.47\n",
      "ok\n",
      "Trying:\n",
      "    score_subjects(df).median()\n",
      "Expecting:\n",
      "    0.0\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "doctest.run_docstring_examples(score_subjects, globals(), verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earn-Back Part 3:\n",
    "\n",
    "Insert the results of your **score_subjects()** function as a new column in your dataframe. Call that new column **Risk Score**\n",
    "You do not need to write a function to this.  Just write this code directly in the cells below.  Provide some minimal documentation to explain what you're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Risk Score'] = score_subjects(df)\n",
    "\n",
    "# new df column called 'Risk Score' is assigned the values in the series produced by the score_subjects function.\n",
    "# since every entry has a score and no sorting was performed, we can directly insert those values into the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Earn-Back Part 4:\n",
    "\n",
    "Summarize your dataframe in the following way. For each **Risk Score** provide the following aggregates:\n",
    "* Count\n",
    "* Average **histogram_number_of_peaks**\n",
    "* Average **acceleration**\n",
    "* Average **light_deceleration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Risk Score\n",
       "0    1341\n",
       "1     574\n",
       "2     210\n",
       "3       1\n",
       "Name: baseline value, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count\n",
    "risk_group = df.groupby('Risk Score')\n",
    "risk_group['baseline value'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Risk Score\n",
       "0    2.384787\n",
       "1    6.576655\n",
       "2    7.952381\n",
       "3    6.000000\n",
       "Name: histogram_number_of_peaks, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average histogram_number_of_peaks\n",
    "risk_group['histogram_number_of_peaks'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Risk Score\n",
       "0    0.002371\n",
       "1    0.004643\n",
       "2    0.004295\n",
       "3    0.011000\n",
       "Name: accelerations, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average accelerations\n",
    "risk_group['accelerations'].agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Risk Score\n",
       "0    0.000675\n",
       "1    0.003051\n",
       "2    0.006448\n",
       "3    0.007000\n",
       "Name: light_decelerations, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average light_decelerations\n",
    "risk_group['light_decelerations'].agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your work to github in your week 11 folder by 11/18 11:59 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
